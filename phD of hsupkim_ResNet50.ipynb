{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7789876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋 폴더 경로\n",
    "dataset_dir = 'dataset'\n",
    "\n",
    "# 클래스 이름\n",
    "class_names = ['M', 'D']\n",
    "\n",
    "# 각 클래스별 파일 경로\n",
    "file_paths = {}\n",
    "for class_name in class_names:\n",
    "    file_paths[class_name] = [os.path.join(dataset_dir, class_name, file_name) for file_name in os.listdir(os.path.join(dataset_dir, class_name))]\n",
    "\n",
    "# 각 클래스별 훈련 데이터와 검증 데이터 비율\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "# 훈련 데이터와 검증 데이터로 나누기\n",
    "train_file_paths = {}\n",
    "val_file_paths = {}\n",
    "for class_name in class_names:\n",
    "    train_files, val_files = train_test_split(file_paths[class_name], train_size=train_ratio, test_size=val_ratio, random_state=42)\n",
    "    train_file_paths[class_name] = train_files\n",
    "    val_file_paths[class_name] = val_files\n",
    "\n",
    "# 훈련 데이터와 검증 데이터 폴더 경로\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'validation')\n",
    "\n",
    "# 각 클래스별 훈련 데이터와 검증 데이터 폴더 생성\n",
    "for class_name in class_names:\n",
    "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
    "\n",
    "# 각 클래스별 훈련 데이터와 검증 데이터 복사\n",
    "for class_name in class_names:\n",
    "    for file_path in train_file_paths[class_name]:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        shutil.copy(file_path, os.path.join(train_dir, class_name, file_name))\n",
    "    for file_path in val_file_paths[class_name]:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        shutil.copy(file_path, os.path.join(val_dir, class_name, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78f0ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = \"dataset\"\n",
    "\n",
    "# 하위 폴더 경로\n",
    "subdirs = ['train/M', 'train/D', 'validation/M', 'validation/D']\n",
    "\n",
    "# 이미지 크기 조정 함수\n",
    "def resize_images(folder_path, new_size=(224, 224)):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path)\n",
    "            img_resized = img.resize(new_size, resample=Image.LANCZOS)\n",
    "            # 파일 확장자 변경\n",
    "            new_filename = os.path.splitext(filename)[0] + \".jpg\"\n",
    "            new_img_path = os.path.join(folder_path, new_filename)\n",
    "            img_resized.save(new_img_path)\n",
    "\n",
    "# 각 하위 폴더 내 이미지 크기 변경 및 확장자 변경\n",
    "for subdir in subdirs:\n",
    "    folder_path = os.path.join(data_dir, subdir)\n",
    "    resize_images(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81b88cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "data_dir = \"dataset\"\n",
    "subdirs = ['train/M', 'train/D', 'validation/M', 'validation/D']\n",
    "\n",
    "def resize_images(folder_path, new_size=(224, 224)):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_resized = img.resize(new_size, resample=Image.LANCZOS)\n",
    " \n",
    "            new_filename = os.path.splitext(filename)[0] + \".jpg\"\n",
    "            new_img_path = os.path.join(folder_path, new_filename)\n",
    "            img_resized.save(new_img_path)\n",
    "\n",
    "for subdir in subdirs:\n",
    "    folder_path = os.path.join(data_dir, subdir)\n",
    "    resize_images(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d08ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 340 images belonging to 2 classes.\n",
      "Found 88 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\AppData\\Local\\Temp\\ipykernel_30144\\4108045270.py:28: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator, steps_per_epoch=len(train_generator), epochs=10, validation_data=val_generator, validation_steps=len(val_generator))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 108s 9s/step - loss: 3.8461 - accuracy: 0.4559 - val_loss: 182749.7031 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 83s 8s/step - loss: 1.7970 - accuracy: 0.5059 - val_loss: 252556.4375 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 78s 7s/step - loss: 1.5019 - accuracy: 0.5206 - val_loss: 114196.2266 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 77s 7s/step - loss: 1.2601 - accuracy: 0.5353 - val_loss: 21081.7617 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 78s 7s/step - loss: 0.8910 - accuracy: 0.5265 - val_loss: 1322.7891 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 78s 7s/step - loss: 1.1126 - accuracy: 0.4941 - val_loss: 0.6938 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 78s 7s/step - loss: 0.8671 - accuracy: 0.5029 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 78s 7s/step - loss: 1.0226 - accuracy: 0.5118 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 66s 6s/step - loss: 1.1368 - accuracy: 0.5235 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 58s 5s/step - loss: 0.7749 - accuracy: 0.5176 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\AppData\\Local\\Temp\\ipykernel_30144\\4108045270.py:31: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  loss, accuracy = model.evaluate_generator(val_generator, steps=len(val_generator))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6931753158569336\n",
      "accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ResNet50 모델 불러오기\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# 새로운 출력층 추가하기\n",
    "x = resnet.output\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=resnet.input, outputs=predictions)\n",
    "\n",
    "# 모델 컴파일하기\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 이미지 데이터 제너레이터 생성하기\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('dataset/train', target_size=(224, 224), batch_size=32, class_mode='binary', color_mode='rgb')\n",
    "val_generator = val_datagen.flow_from_directory('dataset/validation', target_size=(224, 224), batch_size=32, class_mode='binary', color_mode='rgb')\n",
    "\n",
    "# 모델 학습하기\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=len(train_generator), epochs=10, validation_data=val_generator, validation_steps=len(val_generator))\n",
    "\n",
    "# 모델 검증하기\n",
    "loss, accuracy = model.evaluate_generator(val_generator, steps=len(val_generator))\n",
    "print('loss:', loss)\n",
    "print('accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5975c36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.applications.inception_v1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minception_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InceptionV1\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.applications.inception_v1'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v1 import InceptionV1\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# InceptionV1 모델 불러오기\n",
    "inceptionv1 = InceptionV1(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# 새로운 출력층 추가하기\n",
    "x = inceptionv1.output\n",
    "x = Flatten()(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inceptionv1.input, outputs=predictions)\n",
    "\n",
    "# 모델 컴파일하기\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 이미지 데이터 제너레이터 생성하기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('dataset/train', target_size=(224, 224), batch_size=32, class_mode='binary', color_mode='rgb')\n",
    "val_generator = val_datagen.flow_from_directory('dataset/validation', target_size=(224, 224), batch_size=32, class_mode='binary', color_mode='rgb')\n",
    "\n",
    "# 모델 학습하기\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=len(train_generator), epochs=10, validation_data=val_generator, validation_steps=len(val_generator))\n",
    "\n",
    "# 모델 검증하기\n",
    "loss, accuracy = model.evaluate_generator(val_generator, steps=len(val_generator))\n",
    "print('loss:', loss)\n",
    "print('accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7907d1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e13c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
